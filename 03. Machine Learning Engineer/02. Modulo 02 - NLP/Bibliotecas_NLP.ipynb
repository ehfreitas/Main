{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "2a7EoxZ1dO6M"
      },
      "outputs": [],
      "source": [
        "from textblob import TextBlob"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "quote_01 = 'One of the best things in life is to be free.'\n",
        "quote_02 = 'I have waiting too long in queues. Feels like I\\'m wasting my time'\n",
        "quote_03 = 'I cant\\'t imagine a man really enjoying a book and reading it only once.'\n",
        "quote_04 = 'You can never get a cup of tea large enough or a book long enough to suit me'\n",
        "quote_05 = 'Education without values, as useful as it is, seems rather to make a man a more clever devil'"
      ],
      "metadata": {
        "id": "tUnlJ4r6dRkf"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quoteblob_01 = TextBlob(quote_01)\n",
        "quoteblob_02 = TextBlob(quote_02)\n",
        "quoteblob_03 = TextBlob(quote_03)\n",
        "quoteblob_04 = TextBlob(quote_04)\n",
        "quoteblob_05 = TextBlob(quote_05)"
      ],
      "metadata": {
        "id": "ud5zm5TOdzFX"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verifica analise de sentimento nas citações 01 e 02\n",
        "print(quoteblob_01.sentiment) # 'One of the best things in life is to be free.'\n",
        "print(quoteblob_02.sentiment) # 'I have waiting too long in queues. Feels like I\\'m wasting my time'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMqS451pd6xu",
        "outputId": "c584d23e-6730-44ef-c163-89104fabc8df"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment(polarity=0.7, subjectivity=0.55)\n",
            "Sentiment(polarity=-0.05, subjectivity=0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(quoteblob_03.sentiment) # 'I cant\\'t imagine a man really enjoying a book and reading it only once.'\n",
        "print(quoteblob_04.sentiment) # 'You can never get a cup of tea large enough or a book long enough to suit me'\n",
        "print(quoteblob_05.sentiment) # 'Education without values, as useful as it is, seems rather to make a man a more clever devil'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3TrQzOXeGNH",
        "outputId": "3d81cd3b-093a-425e-d143-3df73ad70be6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment(polarity=0.25, subjectivity=0.8)\n",
            "Sentiment(polarity=0.041071428571428564, subjectivity=0.4571428571428572)\n",
            "Sentiment(polarity=0.32222222222222224, subjectivity=0.4444444444444445)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using Google Translator\n",
        "!pip install googletrans==4.0.0rc1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oc1bLmKvem_f",
        "outputId": "781a110c-ebf8-4919-e5f2-1cb3079aa2a4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: googletrans==4.0.0rc1 in /usr/local/lib/python3.10/dist-packages (4.0.0rc1)\n",
            "Requirement already satisfied: httpx==0.13.3 in /usr/local/lib/python3.10/dist-packages (from googletrans==4.0.0rc1) (0.13.3)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0rc1) (3.0.4)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0rc1) (2022.12.7)\n",
            "Requirement already satisfied: httpcore==0.9.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0rc1) (0.9.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0rc1) (1.3.0)\n",
            "Requirement already satisfied: hstspreload in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0rc1) (2023.1.1)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0rc1) (2.10)\n",
            "Requirement already satisfied: rfc3986<2,>=1.3 in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0rc1) (1.5.0)\n",
            "Requirement already satisfied: h11<0.10,>=0.8 in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0rc1) (0.9.0)\n",
            "Requirement already satisfied: h2==3.* in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0rc1) (3.2.0)\n",
            "Requirement already satisfied: hpack<4,>=3.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0rc1) (3.0.0)\n",
            "Requirement already satisfied: hyperframe<6,>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0rc1) (5.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import googletrans\n",
        "from googletrans import Translator as google_translator\n",
        "\n",
        "translator = google_translator()"
      ],
      "metadata": {
        "id": "gCUE_gxJl9Xt"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_01 = 'Friendship is unnecessary, like philosophy, like art.... It has not survival value; rather it is one of those things that give value to survival'\n",
        "result = translator.translate(sentence_01, dest='pt', src='en')\n",
        "print(result.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGBPJKzImZqF",
        "outputId": "8c430772-e393-480a-a102-7400cd08cd74"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A amizade é desnecessária, como a filosofia, como a arte ... não tem valor de sobrevivência;Pelo contrário, é uma daquelas coisas que agregam valor à sobrevivência\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_02 = 'Eu descobri em mim mesmo desejos os quais nada nesta Terra pode satisfazer. A única explicação lógica é que fui feito para outro mundo.'\n",
        "result = translator.translate(sentence_02, dest='en', src='pt')\n",
        "print(result.text)"
      ],
      "metadata": {
        "id": "n0dCVtP8nCcF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8d0e77b-c4a6-42f1-fa4a-7b00845bb641"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I have discovered in myself desires that nothing on this earth can satisfy.The only logical explanation is that I was made to another world.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_03 = 'I believe in Christianity as I believe that the sun has risen: not only because I see it, but because by it I see everything else.'\n",
        "result = translator.translate(sentence_03, dest='it', src='en')\n",
        "print(result.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LXibG_2nzNN",
        "outputId": "49c0777c-ae3a-40eb-8cf2-a9db51cb5358"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Credo nel cristianesimo come credo che il sole sia aumentato: non solo perché lo vedo, ma perché da esso vedo tutto il resto.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using TextBlob Translator\n",
        "from textblob import TextBlob"
      ],
      "metadata": {
        "id": "_QexYLyroNpE"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_01 = u'Friendship is unnecessary, like philosophy, like art... It has not survival value; rather it is one of those things that adds value to survival'\n",
        "language_translator = TextBlob(sentence_01)\n",
        "result = language_translator.translate(from_lang='en', to='pt')\n",
        "print(result)\n",
        "print(result.sentiment)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PO-6_G5uowGz",
        "outputId": "450b477e-c21a-4182-b03d-8a73a2b15b9a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A amizade é desnecessária, como a filosofia, como a arte ... não tem valor de sobrevivência; Pelo contrário, é uma daquelas coisas que agrega valor à sobrevivência\n",
            "Sentiment(polarity=0.0, subjectivity=0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_02 = 'Eu descobri em mim mesmo desejos os quais nada nesta Terra pode satisfazer. A única explicação lógica é que fui feito para outro mundo.'\n",
        "language_translator = TextBlob(sentence_02)\n",
        "result = language_translator.translate(from_lang='pt', to='en')\n",
        "print(result)\n",
        "print(result.sentiment)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FivZjbbpTeU",
        "outputId": "ce14a99c-e478-4b52-9cee-dfb19173bb88"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I have discovered in myself desires that nothing on this earth can satisfy. The only logical explanation is that I was made to another world.\n",
            "Sentiment(polarity=0.125, subjectivity=0.625)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_03 = 'I believe in Christianity as I believe that the sun has risen: not only because I see it, but because by it I see everything else.'\n",
        "language_translator = TextBlob(sentence_03)\n",
        "result = language_translator.translate(from_lang='en', to='it')\n",
        "print(result)\n",
        "print(result.sentiment)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MI8TE8p3psOU",
        "outputId": "d8a58d51-87ed-4f08-c4fb-2ac1565b221d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Credo nel cristianesimo come credo che il sole sia aumentato: non solo perché lo vedo, ma perché da esso vedo tutto il resto.\n",
            "Sentiment(polarity=0.0, subjectivity=0.25)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using spaCy (NLP library for Python)\n",
        "!python -m spacy download pt\n",
        "import spacy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ary2Gn6dqG5E",
        "outputId": "5189fcb3-8cfd-4861-b91a-354a1a525a81"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-04-28 21:01:06.454372: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-28 21:01:07.634251: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'pt' are deprecated. Please use the\n",
            "full pipeline package name 'pt_core_news_sm' instead.\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pt-core-news-sm==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.5.0/pt_core_news_sm-3.5.0-py3-none-any.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from pt-core-news-sm==3.5.0) (3.5.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (1.10.7)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (0.7.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (23.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (0.10.1)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (8.1.9)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (1.1.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (67.7.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (2.4.6)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->pt-core-news-sm==3.5.0) (2.1.2)\n",
            "Installing collected packages: pt-core-news-sm\n",
            "Successfully installed pt-core-news-sm-3.5.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('pt_core_news_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp_en = spacy.load(\"en_core_web_sm\")\n",
        "nlp_pt = spacy.load('pt_core_news_sm')"
      ],
      "metadata": {
        "id": "fmQxUtzDqq9z"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_en = 'A children\\'s story that can only be enjoyed by children is not a good children\\'s story in the slightest.'\n",
        "result = nlp_en(sentence_en)\n",
        "[(token.text, token.pos_) for token in result]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paMviioXq6or",
        "outputId": "ad36a78a-0208-415e-e012-6007837f76d5"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('A', 'DET'),\n",
              " ('children', 'NOUN'),\n",
              " (\"'s\", 'PART'),\n",
              " ('story', 'NOUN'),\n",
              " ('that', 'PRON'),\n",
              " ('can', 'AUX'),\n",
              " ('only', 'ADV'),\n",
              " ('be', 'AUX'),\n",
              " ('enjoyed', 'VERB'),\n",
              " ('by', 'ADP'),\n",
              " ('children', 'NOUN'),\n",
              " ('is', 'AUX'),\n",
              " ('not', 'PART'),\n",
              " ('a', 'DET'),\n",
              " ('good', 'ADJ'),\n",
              " ('children', 'NOUN'),\n",
              " (\"'s\", 'PART'),\n",
              " ('story', 'NOUN'),\n",
              " ('in', 'ADP'),\n",
              " ('the', 'DET'),\n",
              " ('slightest', 'ADJ'),\n",
              " ('.', 'PUNCT')]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_pt = 'Tudo que é eterno está eternamente acima do tempo.'\n",
        "result = nlp_pt(sentence_pt)\n",
        "[(token.text, token.pos_) for token in result]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQeQQk37rcuz",
        "outputId": "8837c912-f3cc-4ea8-fecf-377edcef5d3c"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Tudo', 'PRON'),\n",
              " ('que', 'PRON'),\n",
              " ('é', 'AUX'),\n",
              " ('eterno', 'NOUN'),\n",
              " ('está', 'AUX'),\n",
              " ('eternamente', 'ADV'),\n",
              " ('acima', 'ADV'),\n",
              " ('do', 'ADP'),\n",
              " ('tempo', 'NOUN'),\n",
              " ('.', 'PUNCT')]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_pt = 'Mera mudança não é crescimento. Crescimento é a síntese de mudança e continuidade, e onde há continuidade'\n",
        "result = nlp_pt(sentence_pt)\n",
        "tokens = [token for token in result]\n",
        "\n",
        "print(tokens[1], tokens[9], tokens[1].similarity(tokens[9]))\n",
        "print(tokens[11], tokens[13], tokens[11].similarity(tokens[13]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLOiGuH8s5jj",
        "outputId": "a5495e76-b4cb-481d-88c6-184403cae5e8"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mudança síntese 0.3977940082550049\n",
            "mudança continuidade 0.528011679649353\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-50-bd24c1b176f2>:5: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  print(tokens[1], tokens[9], tokens[1].similarity(tokens[9]))\n",
            "<ipython-input-50-bd24c1b176f2>:6: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  print(tokens[11], tokens[13], tokens[11].similarity(tokens[13]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "30sqJ9qath7s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}